\chapter{Curvilinear FEM}
\label{chap:curvilinear_fem}

\section{Notational conventions}

Things are going to get seriously hirsute here.  I've been liberal with my use of boldface vector notation in my first drafts.  On the one hand, I have the coordinate transformations $\ve X$ and $\ve R$, which are boldfaced because they produce Cartesian vectors $(x,y)$ and $(r,s)$, respectively.  On the other hand each element has two arrays of nodal coordinates $\ve r$ and $\ve s$ which are boldfaced because I manipulate all the $r$ coordinates together as a single column vector and all the $s$ coordinates together likewise.  I will lose my mind if I keep this up.  Because my Cartesian vectors will have no more than 3 elements each, the pain of writing them out explicitly is somewhat less than the pain of writing out $N$ values at a time for $N$ nodes ($N \ge 3$ no matter what).  So where possible, from now on, boldface notation is used for quantities which are sampled at multiple points in space---unless otherwise noted.

\section{Curvilinear coordinates}

Dear reader, run out there and educate yourself on what ``isoparametric,'' ``superparametric'' and ``subparametric'' mean, and return here enlightened.  Remind me whether the polyhedral geometries of the previous sections are superparametric or subparametric, and provide a foolproof mnemonic to prevent me from ever forgetting again.

The forward coordinate transformation $\ve X(\ve r)$ of chapter \ref{chap:preliminaries} (Figure \ref{fig:reference_simplex}) and its inverse $\ve R(\ve x)$ are linear.  We now consider a polynomial forward coordinate transformation and its inverse,
%
\begin{equation}
\begin{bmatrix}
x \\ y
\end{bmatrix}
=
\begin{bmatrix}
X(r, s) \\ Y(r,s)
\end{bmatrix},
\qquad
\begin{bmatrix}
r \\ s
\end{bmatrix}
=
\begin{bmatrix}
R(x, y) \\ S(x,y)
\end{bmatrix}.
\end{equation}
%
When $X$ and $Y$ are polynomial functions of $r$ and $s$, $R$ and $S$ are not in general polynomials.  (Consider $X(r) = r^2$ and its non-polynomial inverse mapping $R(x) = \sqrt{x}$.)  I think we'll have to invert them numerically with \emph{e.g.} Newton's method.

Define the coordinate transformations using nodal polynomials by the usual scheme.  Within a single element let the nodal coordinates in the reference simplex be $\n{\ve r}, \n{\ve s}$ which map to $\n{\ve x}, \n{\ve y}$.  Then to evaluate at query points $\q{\ve r}, \q{\ve s}$ use interpolation,
%
\begin{equation}
\begin{aligned}
X(\q{\ve r}, \q{\ve s}) &= V(\q{\ve r}, \q{\ve s}) V(\n{\ve r}, \n{\ve s})^{-1} \n{\ve x} \\
Y(\q{\ve r}, \q{\ve s}) &= V(\q{\ve r}, \q{\ve s}) V(\n{\ve r}, \n{\ve s})^{-1} \n{\ve y}.
\end{aligned}
\end{equation}

\subsection{Interpolation}

I am tinkering with good notations for the interpolation operator.  How is this:
%
\begin{equation}
\boxed{
I(\ve r, \ve s) = V(\ve r, \ve s) V(\n{\ve r}, \n{\ve s})^{-1}
}% boxed
\end{equation}
%
meaning an operator interpolating values on nodes to $\ve r, \ve s$.  Differentiation in the reference simplex is accomplished by the operators $D_r = \partial_r I$ and $D_s = \partial_s I$.  Also $I(\n{\ve r}, \n{\ve s}) \equiv \mathbb{1}$.

The forward coordinate transformation is an interpolation.
%
\begin{equation}
\boxed{
\begin{aligned}
X(\q{\ve r}, \q{\ve s}) &= I(\q{\ve r}, \q{\ve s}) \n{\ve x} \\
Y(\q{\ve r}, \q{\ve s}) &= I(\q{\ve r}, \q{\ve s}) \n{\ve y}.
\end{aligned}
}%boxed
\end{equation}

\subsection{Jacobian}
\label{sec:curvilinear_jacobian}

The Jacobian of the forward transformation is
%
\begin{equation}
J(\q r, \q s) =
\begin{bmatrix}
\partial_r X(\q r, \q s) & \partial_s X(\q r, \q s) \\
\partial_r Y(\q r, \q s) & \partial_s Y(\q r, \q s)
\end{bmatrix}
=
\begin{bmatrix}
\partial_r I(\q r, \q s) \n{\ve x} & \partial_s I(\q r, \q s) \n{\ve x} \\
\partial_r I(\q r, \q s) \n{\ve y} & \partial_s I(\q r, \q s) \n{\ve y}
\end{bmatrix}
\end{equation}

\subsection{Inverse coordinate transform}

To evaluate $R(x,y)$ and $S(x,y)$ numerically, how about Newton's method?  Start with a linear guess---or any guess inside the simplex probably---and iterate:
%
\begin{equation}
\boxed{
\begin{bmatrix} r_{n+1} \\ s_{n+1} \end{bmatrix}
=
\begin{bmatrix} r_n \\ s_n \end{bmatrix}
-
J(r_n, s_n)^{-1}
%\begin{bmatrix} \partial_r X(r_n, s_n) & \partial_s X(r_n, s_n) \\ \partial_r Y(r_n, s_n) & \partial_s Y(r_n, s_n) \end{bmatrix}^{-1}
\begin{bmatrix}X(r_n, s_n) - x \\ Y(r_n, s_n) - y \end{bmatrix}.
}%boxed
\end{equation}
%
My gut feeling is that this will converge to the correct $(r,s)$ for any initial guess inside the simplex, as long as the element is not inverted.

\section{Nodal sets}

Following \cite{hesthaven2007nodal}, the order of an element is specified by the number of elements $N$ along one of its edges, including vertex nodes.  Nodal coordinates $\ve r, \ve s$ are given by the warping recipe from \cite{hesthaven2007nodal}.  For now I'll assume that an element has the same number of nodes along each of its edges.

There are three nodal sets of interest.
%
\begin{enumerate}
  \item $\f{\ve r}, \f{\ve s}$: the $field$ nodes where the solution (\emph{e.g.} electrostatic potential) is defined, with $N_f$ samples on each element edge,
  \item $\g{\ve r}, \g{\ve s}$: the \emph{geometry} nodes where the nodal positions $\g{\ve x}, \g{\ve y}$ are specified, with $N_g$ samples per edge,
  \item $\q{\ve r}, \q{\ve s}$: the \emph{quadrature} nodes where functions are sampled for numerical integration, with $N_q$ samples per edge.
\end{enumerate}
%
Isoparametric formulations of FEM will have $N_f = N_g$.  I've read that low-order quadrature formulae work ok as long as the elements are affine ($N_g = 2$) but higher-order curvilinear quadrature needs more samples.  So I think I will have a set of quadrature nodes with $N_q > N_f, N_g$.

\section{Vandermonde matrices}

Vandermonde matrices are always defined on the reference element, independent of whether the mesh is curvilinear or just affine.  A nodal set of order $N$ has $\frac{N(N+1)}{2}$ nodes and $\frac{N(N+1)}{2}$ orthonormal basis polynomials.  An element of order $N+1$ shares the first $\frac{N(N+1)}{2}$ basis polynomials with an element of order $N$, and adds on a few more with higher polynomial order.  There is a name for this property of the basis functions and some FEM formulations do not have this (useful) feature.

A Vandermonde matrix maps modal coefficients to nodal values.  Its general form for $n$ nodes and $m$ basis polynomials is
%
\begin{equation}
V(\ve r, \ve s) =
\begin{bmatrix}
\phi_1(r_1, s_1) & \phi_2(r_1, s_1) & \cdots & \phi_m(r_1, s_1) \\
\phi_1(r_2, s_2) & \phi_2(r_2, s_2) & \cdots & \phi_m(r_2, s_2) \\
\vdots & \vdots & \ddots & \vdots \\
\phi_1(r_n, s_n) & \phi_2(r_n, s_n) & \cdots & \phi_m(r_n, s_n)
\end{bmatrix}.
\end{equation}
%
Several Vandermonde matrices will be of interest for curvilinear FEM.
%
\begin{enumerate}
  \item $V_f(\ve r, \ve s)$ evaluates modes 1 through $\frac{N_f(N_f+1)}{2}$ on points $\ve r, \ve s$.  The symbol $V_f$ alone will refer to the square matrix $V_f(\f{\ve r}, \f{\ve s})$, the usual Vandermonde matrix of the previous chapters.
  \item $V_g(\ve r, \ve s)$ evaluates modes 1 through $\frac{N_g(N_g+1)}{2}$ on points $\ve r, \ve s$.  The symbol $V_g$ alone means the square matrix $V_g(\g{\ve r}, \g{\ve s})$.
  \item $V_q(\ve r, \ve s)$ evaluates modes 1 through $\frac{N_q(N_q+1)}{2}$ on points $\ve r, \ve s$.  The symbol $V_q$ alone means the square matrix $V_q(\q{\ve r}, \q{\ve s})$.  This should be the biggest matrix since we need lots of quadrature points.
\end{enumerate}
%
Furthermore the shorthand notations $V_{f \rightarrow g} \equiv V_f(\g{\ve r}, \g{\ve s})$ and other similar symbols might be used from time to time.

\subsection{Notations for interpolation}

Here is some similar shorthand for interpolation.
%
\begin{enumerate}
  \item $I_f(\ve r, \ve s) \equiv V_f(\ve r, \ve s) V_f^{-1}$, and similarly $I_g(\ve r, \ve s)$ and $I_q(\ve r, \ve s)$, interpolating certain nodal values to arbitrary coordinates
  \item $I_{f \rightarrow g} \equiv V_{f \rightarrow g} V_f^{-1}$ and other such symbols, interpolating values on one nodal set to another nodal set.
\end{enumerate}

\subsection{Cautionary note for quadrature}

What is the best approach for mapping field nodal values to quadrature modal coefficients?  This is a bad case because the higher-order quadrature modes will become linearly dependent with lower-order modes when evaluated on a smaller set of field nodes.  The simplest calculation of quadrature modal coefficients is
%
\begin{equation}
\q{\hat u} = V_{q \rightarrow f}^+ \f{\ve u}.
\end{equation}
%
I haven't tested this but I suspect it will populate higher order modes even if the field nodes can only resolve quadratics.  We can force it to do better:
%
\begin{equation}
\q{\hat u} = V_q^{-1} V_{f \rightarrow q} V_f^{-1} \f{\ve u} = V_q^{-1} I_{f \rightarrow q} \f{\ve u}.
\end{equation}
%
If the field nodes only resolve quadratics, this will smoothly evaluate a quadratic at finely-spaced quadrature points, then correctly produce the quadratic coefficients and zero-out the cubic and higher order coefficients.

\section{Quadrature}

Although quadrature can be performed on any nodal set let's assume I will use high-density quadrature nodes whenever curvilinear elements are involved.  In the reference simplex\footnote{My notation is looking more and more ridiculous.},
%
\begin{equation}
\int_\bigtriangleup dr\, ds\, f(r,s) g(r,s) = \q{\ve f^T} V_q^{-T} V_q^{-1} \q{\ve g}.
\end{equation}
%
In $xy$ space we need the determinant of the Jacobian.  First obtain the pointwise Jacobian at all quadrature nodes.
%
\begin{equation}
J(\q{\ve r}, \q{\ve s}) =
\begin{bmatrix}
\partial_r I_{g \rightarrow q} \g{\ve x} & \partial_s I_{g \rightarrow q} \g{\ve x} \\
\partial_r I_{g \rightarrow q} \g{\ve y} & \partial_s I_{g \rightarrow q} \g{\ve y}
\end{bmatrix}
\end{equation}
%
Then the pointwise determinant can be denoted $| \q{\ve{J}} |$.  Combine it with the quadrature kernel as a diagonal matrix.  Now we can integrate in $xy$ space:
%
\begin{equation}
\begin{aligned}
\int_\bigtriangleup dx \, dy \, f(x,y) g(x,y) &= \int_\bigtriangleup dr \, ds \, |J| f(r,s) g(r,s) \\
&= \q{\ve f^T} V_q^{-T} V_q^{-1} \operatorname{diag}\{| \q{\ve J}|\} \q{\ve g} \\
&= \f{\ve f^T} I_{f \rightarrow q}^T V_q^{-T} V_q^{-1} \operatorname{diag}\{| \q{\ve J}|\} I_{f \rightarrow q} \f{\ve g}.
\end{aligned}
\end{equation}
%
In the last line I've assumed the usual situation where $f$ and $g$ are known only at field nodes and need to be interpolated to quadrature points.

The quadrature matrix in $xy$ space is
%
\begin{equation}
\boxed{
Q \equiv I_{f \rightarrow q}^T V_q^{-T} V_q^{-1} \operatorname{diag}\{| \q{\ve J}|\} I_{f \rightarrow q}.
}%boxed
\end{equation}

For sensitivity analyses later I will differentiate $Q$ with respect to $\g{\ve x}$ and $\g{\ve y}$.  God save me, I will see it through!

\section{Differentiation}

The differentiation operator has already shown its ugly mug in subsection \ref{sec:curvilinear_jacobian}.  It has become easy.  For instance on field nodes, the partial derivative with respect to $r$ obtained by
%
\begin{equation}
\f{D}_r(\ve r, \ve s) = \partial_r I_f(\ve r, \ve s) = \partial_r V_f(\ve r, \ve s) V_f^{-1}.
\end{equation}
%
Differentiation in $xy$ space uses the pointwise Jacobian.  I wrote that formula out before in Chapter \ref{chap:preliminaries} but I can update the notation now.

By the chain rule, $\nabla_{rs} f = (\nabla_{xy}f)J$, so $\nabla_{xy}f = (\nabla_{rs} f) J^{-1}$.  Let's write out the terms and discretize everything.  Let the inverse Jacobian be $K(r,s)$:
%
\begin{equation}
K(r,s) = J(r,s)^{-1} = \begin{bmatrix}
k_{11}(r,s) & k_{12}(r,s) & \hdots \\
k_{21}(r,s) & k_{22}(r,s) & \hdots \\
\vdots & \vdots & \ddots
\end{bmatrix}.
\end{equation}
%
Then the partial derivative operators are
%
\begin{equation}
\begin{aligned}
\partial_x = k_{11}(r,s) \partial_r + k_{21}(r,s) \partial_s \\
\partial_y = k_{12}(r,s) \partial_r + k_{22}(r,s) \partial_s.
\end{aligned}
\end{equation}
%
We will calculate $rs$ gradients in single elements using the differentiation matrices and linearly combine them pointwise to obtain $xy$ gradients.
%
\begin{equation}
\boxed{
\begin{aligned}
D_x &= \mathrm{diag}(\ve k_{11}) D_r + \mathrm{diag}(\ve k_{21}) D_s \\
D_y &= \mathrm{diag}(\ve k_{12}) D_r + \mathrm{diag}(\ve k_{22}) D_s .
\end{aligned}
}
%\label{eqn:partialDerivatives}
\end{equation}

\section{Sensitivity to nodal perturbations}

A shape sensitivity is a derivative with respect to geometry node coordinates, $\partial/\partial \g{\ve x}$ or $\partial/\partial \g{\ve y}$.  Basically every quantity and operation of interest in curvilinear FEM must be differentiated with respect to nodal coordinates in order to obtain the shape sensitivity of some objective function of the fields.  All shape dependence comes from the coordinate transformations $X(r,s)$ and $Y(r,s)$ and their shape sensitivities.

\subsection{Coordinate transformation sensitivity}
The shape sensitivities of the forward coordinate transformation turn out to be the interpolation matrices, for instance:
%
\begin{equation}
\pp{}{\g{\ve x}}X(r,s) = \pp{}{\g{\ve x}}I_g(r,s) \g{\ve x} = I_g(r,s) \mathbb{1} = I_g(r,s).
\end{equation}
%
The sensitivities of $X(\ve r, \ve s)$ and $Y(\ve r, \ve s)$ together to $\g{\ve x}$ and $\g{\ve y}$ are
%
\begin{equation}
\boxed{
\begin{bmatrix}
\pp{X(\ve r,\ve s)}{\g{\ve x}} & \pp{X(\ve r,\ve s)}{\g{\ve y}} \\
\pp{Y(\ve r,\ve s)}{\g{\ve x}} & \pp{Y(\ve r,\ve s)}{\g{\ve y}}
\end{bmatrix}
=
\begin{bmatrix}
I_g(\ve r,\ve s) & \mathbb{0} \\
\mathbb{0} & I_g(\ve r,\ve s)
\end{bmatrix}.
}%boxed
\end{equation}

The sensitivity of the inverse transforms $R(x,y)$ and $S(x,y)$ to arbitrary parameter changes were derived before (Equation \ref{eqn:inverse_transformation_derivative}).  In the new-style notation, for a single point $(r,s) = (R(x,y), S(x,y))$,
%
\begin{equation}
\begin{bmatrix} \pp{R(x,y)}{p} \\ \pp{S(x,y)}{p} \end{bmatrix}
=
-K(r,s)
\begin{bmatrix}
\pp{X(r,s)}{p} \\ \pp{Y(r,s)}{p}
\end{bmatrix}.
\end{equation}
%
It follows that
%
\begin{equation}
\boxed{
\begin{bmatrix}
\pp{R(\ve x,\ve y)}{\g{\ve x}} & \pp{R(\ve x,\ve y)}{\g{\ve y}} \\
\pp{S(\ve x,\ve y)}{\g{\ve x}} & \pp{S(\ve y,\ve y)}{\g{\ve y}}
\end{bmatrix}
=
-\begin{bmatrix}
\operatorname{diag}(\ve{k}_{11}) I_g(\ve r, \ve s) & \operatorname{diag}(\ve{k}_{12}) I_g(\ve r, \ve s) \\
\operatorname{diag}(\ve{k}_{21}) I_g(\ve r, \ve s) & \operatorname{diag}(\ve{k}_{22}) I_g(\ve r, \ve s)
\end{bmatrix}.
}%boxed
\end{equation}












